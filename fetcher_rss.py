#!/usr/bin/env python3
"""
é©¬æ–¯å…‹æ¨æ–‡ RSS ç›‘æ§è„šæœ¬ v2
ä½¿ç”¨ Nitter/XCancel RSS è®¢é˜…è·å–æœ€æ–°æ¨æ–‡
"""

import feedparser
import requests
import json
from datetime import datetime

# Config
OUTPUT_FILE = "/home/admin/polymarket_musk_monitor/tweets.json"

# å¤šä¸ª RSS æºï¼Œä¾æ¬¡å°è¯•
RSS_SOURCES = [
    "https://xcancel.com/elonmusk/rss",
    "https://nitter.privacydev.net/elonmusk/rss",
    "https://nitter.poast.org/elonmusk/rss",
]

# è®°å½•ä¸Šæ¬¡æ¨æ–‡ ID
LAST_TWEET_LINK = None

def get_tweets_from_rss():
    """ä» RSS æºè·å–æ¨æ–‡"""
    tweets = []
    source_used = None
    
    for rss_url in RSS_SOURCES:
        try:
            print(f"å°è¯•: {rss_url}")
            # ä½¿ç”¨ requests è·å–å†…å®¹
            resp = requests.get(rss_url, timeout=30, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if resp.status_code != 200:
                print(f"âœ— HTTP {resp.status_code}: {rss_url}")
                continue
            
            # è§£æ RSS
            feed = feedparser.parse(resp.text)
            
            if feed.entries:
                print(f"âœ“ æˆåŠŸè·å– {len(feed.entries)} æ¡æ¨æ–‡")
                source_used = rss_url
                for entry in feed.entries[:10]:
                    # æå–æ¨æ–‡å†…å®¹
                    title = entry.get('title', '')
                    # æ¸…ç†æ ‡é¢˜ï¼Œå»æ‰ç”¨æˆ·åå‰ç¼€
                    if 'Elon Musk (@elonmusk): ' in title:
                        content = title.replace('Elon Musk (@elonmusk): ', '')
                    else:
                        content = title
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤
                    is_reply = title.startswith('R to @')
                    
                    tweets.append({
                        'id': len(tweets) + 1,
                        'content': content.strip(),
                        'link': entry.get('link', ''),
                        'published': entry.get('published', ''),
                        'username': 'Elon Musk',
                        'handle': '@elonmusk',
                        'is_reply': is_reply,
                        'source': rss_url
                    })
                break
            else:
                print(f"âœ— æ— æ•°æ®: {rss_url}")
        except Exception as e:
            print(f"âœ— å¤±è´¥: {rss_url} - {str(e)[:50]}")
            continue
    
    return tweets, source_used

def check_updates():
    """æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¨æ–‡"""
    global LAST_TWEET_LINK
    
    print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] æ£€æŸ¥æ¨æ–‡...")
    
    tweets, source = get_tweets_from_rss()
    
    if not tweets:
        print("æ‰€æœ‰ RSS æºéƒ½å¤±è´¥ï¼Œä¿å­˜ç©ºæ•°æ®")
        source = "none"
    
    # è¿‡æ»¤å›å¤ï¼ˆå¦‚æœ polymarket ä¸è®¡å›å¤ï¼‰
    original_tweets = [t for t in tweets if not t['is_reply']]
    reply_count = len(tweets) - len(original_tweets)
    
    # æ£€æŸ¥æ–°æ¨æ–‡
    new_tweets = []
    if tweets and LAST_TWEET_LINK:
        for tweet in tweets:
            if tweet['link'] != LAST_TWEET_LINK:
                new_tweets.append(tweet)
    elif tweets:
        new_tweets = [tweets[0]]
    
    if new_tweets:
        print(f"ğŸ‰ æ£€æµ‹åˆ° {len(new_tweets)} æ¡æ–°æ¨æ–‡!")
        for t in new_tweets:
            print(f"  - {t['content'][:60]}...")
        if tweets:
            LAST_TWEET_LINK = tweets[0]['link']
    else:
        print("æœªæ£€æµ‹åˆ°æ–°æ¨æ–‡")
    
    # ä¿å­˜æ•°æ®
    data = {
        'last_updated': datetime.now().isoformat(),
        'count': len(tweets),
        'original_count': len(original_tweets),
        'reply_count': reply_count,
        'source': source,
        'new_tweets': len(new_tweets),
        'tweets': tweets
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"å·²ä¿å­˜: {len(tweets)} æ¡æ¨æ–‡ ({len(original_tweets)} æ¡åŸåˆ›, {reply_count} æ¡å›å¤)")

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œä¸€æ¬¡æ£€æŸ¥"""
    global LAST_TWEET_LINK
    
    # è¯»å–ä¸Šæ¬¡ä¿å­˜çš„æ¨æ–‡ ID
    try:
        with open(OUTPUT_FILE, 'r') as f:
            old_data = json.load(f)
            if old_data.get('tweets'):
                LAST_TWEET_LINK = old_data['tweets'][0].get('link')
                print(f"ä»ç¼“å­˜æ¢å¤ï¼Œä¸Šæ¬¡æœ€æ–°æ¨æ–‡: {LAST_TWEET_LINK[:50]}...")
    except:
        pass
    
    check_updates()

if __name__ == "__main__":
    main()
